{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NLRxZoBj_jDo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import TFRobertaForSequenceClassification, RobertaTokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"train.csv\") \n",
        "\n",
        "# Preprocess the dataset\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split into training and validation sets (80% for training, 20% for validation)\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQHef7tBnRCs",
        "outputId": "49874d09-340c-4648-fd21-d1a8b0998960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "# Check for available devices\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    print(\"GPU is NOT available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7q2rc2nDEuJV"
      },
      "outputs": [],
      "source": [
        "# Load the RoBERTa tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Tokenize the training data\n",
        "train_encodings = tokenizer(\n",
        "    train_df['Claim'].tolist(),\n",
        "    train_df['Evidence'].tolist(),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='tf'\n",
        ")\n",
        "\n",
        "# Tokenize the validation data\n",
        "val_encodings = tokenizer(\n",
        "    val_df['Claim'].tolist(),\n",
        "    val_df['Evidence'].tolist(),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='tf'\n",
        ")\n",
        "\n",
        "# Create tf.data.Dataset for training and validation\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    train_encodings['input_ids'],\n",
        "    train_df['label'].tolist()\n",
        ")).batch(16)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    val_encodings['input_ids'],\n",
        "    val_df['label'].tolist()\n",
        ")).batch(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d6jxaJxE3vV",
        "outputId": "92bf8201-89ef-42ad-ce03-1134e5282447"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model with binary classification\n",
        "model = TFRobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=1)\n",
        "\n",
        "# Compile the model with binary cross-entropy and an Adam optimizer\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),  \n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO3E7W6gFYSJ",
        "outputId": "4ba58435-2971-4f6a-cf31-0462a0026b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1186/1186 [==============================] - 1766s 1s/step - loss: 0.5351 - accuracy: 0.7413 - val_loss: 0.3978 - val_accuracy: 0.8235\n",
            "Epoch 2/3\n",
            "1186/1186 [==============================] - 1667s 1s/step - loss: 0.3238 - accuracy: 0.8479 - val_loss: 0.3368 - val_accuracy: 0.8606\n",
            "Epoch 3/3\n",
            "1186/1186 [==============================] - 1669s 1s/step - loss: 0.2465 - accuracy: 0.8886 - val_loss: 0.3312 - val_accuracy: 0.8599\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x797ad4133970>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_dataset, validation_data=val_dataset, epochs=3)# Fine-Tune the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OMoCt0LduhMx"
      },
      "outputs": [],
      "source": [
        "# Load the dev dataset for evaluation\n",
        "dev_data = pd.read_csv(\"dev.csv\")\n",
        "\n",
        "df = pd.DataFrame(data) # Preprocess the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eLGPppcutfH",
        "outputId": "9f7f710f-cd10-421b-951f-d6ba8d62a109"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1482/1482 [==============================] - 632s 418ms/step - loss: 0.2070 - accuracy: 0.9219\n",
            "Test Loss: 0.2070\n",
            "Test Accuracy: 0.9219\n"
          ]
        }
      ],
      "source": [
        "#Tokenize the dev dataset inputs\n",
        "dev_encodings = tokenizer(\n",
        "    df['Claim'].tolist(),\n",
        "    df['Evidence'].tolist(),\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Create a TensorFlow dataset for dev\n",
        "dev_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dev_encodings['input_ids'],  # Tokenized input data\n",
        "    df['label'].tolist()  # Corresponding labels\n",
        ")).batch(16)\n",
        "\n",
        "# Evaluate the model to get test loss and accuracy\n",
        "test_loss, test_accuracy = model.evaluate(dev_dataset)\n",
        "\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UshBk7iLGlj6",
        "outputId": "0041e233-97f7-43c8-aff9-9f8727ffa17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1482/1482 [==============================] - 611s 412ms/step\n",
            "Precision: 0.7821616758771366, Recall: 0.9364517618095092, F1-score: 0.8523809523809524\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Predict the logits from the model\n",
        "predicted_logits = model.predict(dev_dataset).logits  # Get logits\n",
        "\n",
        "# Convert logits to probabilities\n",
        "predicted_probabilities = tf.nn.sigmoid(predicted_logits)\n",
        "\n",
        "# Convert probabilities to binary predictions (threshold at 0.5)\n",
        "y_pred = (predicted_probabilities > 0.5).numpy().astype(int)  # Convert to integers\n",
        "\n",
        "y_test = df['label'].tolist() # Get the true labels\n",
        "\n",
        "precision = precision_score(y_test, y_pred) # Calculate precision\n",
        "recall = recall_score(y_test, y_pred) # Calculate recall\n",
        "f1 = f1_score(y_test, y_pred) # Calculate F1-score\n",
        "\n",
        "print(f'Precision: {precision}, Recall: {recall}, F1-score: {f1}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xr4Lgr_hTVij"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Path to the desired folder in Google Drive\n",
        "drive_folder_path = \"/content/drive/MyDrive/my_models\"\n",
        "\n",
        "# Create the folder if it doesn't exist\n",
        "if not os.path.exists(drive_folder_path):\n",
        "    os.makedirs(drive_folder_path)\n",
        "\n",
        "# Save the model to the folder\n",
        "model.save(f\"{drive_folder_path}/roberta_saved_model\", save_format=\"tf\")  # Save the model in the SavedModel format\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
