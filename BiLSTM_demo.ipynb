{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgHGkHlYOjny",
        "outputId": "9e4fc689-f2bf-4480-be5c-d80a2c4f2514"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VVkZ91GaHVc1"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "test_data['Evidence'] = test_data['Evidence'].fillna('')\n",
        "\n",
        "# Tokenize and encode sequences with separator token\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['Claim'] + ' [SEP] ' + data['Evidence'])\n",
        "X_test = tokenizer.texts_to_sequences(test_data['Claim'] + ' [SEP] ' + test_data['Evidence'])\n",
        "X_test = pad_sequences(X_test, maxlen=308)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model\n",
        "model = load_model('best_model.h5')\n",
        "\n",
        "# Generate predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.round(y_pred) # Convert probabilities to binary predictions\n",
        "y_pred=y_pred.astype(int) # Convert predictions to integers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yrMDQUkMAzC",
        "outputId": "bbfc0f3e-1575-4efd-c507-0126ff54a4fd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "147/147 [==============================] - 29s 189ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with predictions\n",
        "predictions_df = pd.DataFrame(y_pred, columns=['prediction'])\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "predictions_df.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "dYsb6SZ3NmT9"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}